"""
Naver Place ë¦¬ë·° íƒœê·¸ í¬ë¡¤ë§ & ê°€ê²Œ í”„ë¡œí•„ ë¹Œë”

ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤(m.place.naver.com)ì˜ **ë¦¬ë·° íƒœê·¸ ì¹©(â€œâ€¦ìš”â€)**ì„ ìˆ˜ì§‘í•´
ê°€ê²Œ ë‹¨ìœ„ë¡œ íƒœê·¸ ë¹ˆë„ë¥¼ ì§‘ê³„í•˜ê³ , JSON/CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.

â–¶ ì‹¤í–‰ë°©ë²•
(1) ì°½ ë„ì›Œì„œ í…ŒìŠ¤íŠ¸
python make_place_profile.py \
  --place_id 1108161508 \ ğŸ“Œ ğŸ“Œ í¬ë¡¤ë§ í•˜ë ¤ëŠ” ê°€ê²Œ id ê¼­ ë°”ê¿”ì„œ ë„£ì–´ì£¼ì„¸ìš”ğŸ“Œ ğŸ“Œ 
  --store_name "ì˜¤ë¸”ë¦¬ë„" \ ğŸ“Œ ğŸ“Œ í¬ë¡¤ë§ í•˜ë ¤ëŠ” ê°€ê²Œì´ë¦„ ê¼­ ë°”ê¿”ì„œ ë„£ì–´ì£¼ì„¸ìš”ğŸ“Œ ğŸ“Œ 
  --cuisine "íŒŒìŠ¤íƒ€","ìŠ¤íŒŒê²Œí‹°" ğŸ“Œ ğŸ“Œ í¬ë¡¤ë§ í•˜ë ¤ëŠ” ê°€ê²Œ ì—…ì¢… ê¼­ ë°”ê¿”ì„œ ë„£ì–´ì£¼ì„¸ìš”ğŸ“Œ ğŸ“Œ 

(2) í—¤ë“œë¦¬ìŠ¤ + ë¦¬ë·° ë‚´ë¶€ ì¤‘ë³µíƒœê·¸ëŠ” 1íšŒë§Œ ì§‘ê³„ + CSVë„ ì €ì¥
python make_place_profile.py \
  --place_id 1108161508 \
  --store_name "ì˜¤ë¸”ë¦¬ë„" \
  --cuisine íŒŒìŠ¤íƒ€ ìŠ¤íŒŒê²Œí‹° \
  --headless --dedup --save_csv

(3) ì‰˜ ì¸ìš©(quoting)
- macOS/Linux(zsh/bash): ê³µë°±/ì‰¼í‘œê°€ ìˆì„ ë• ë”°ì˜´í‘œ ê¶Œì¥.  
ì˜ˆ) --store_name "ì˜¤ë¸”ë¦¬ë„"

- ğŸ“Œ ğŸ“Œ Windows PowerShell: âœ… í°ë”°ì˜´í‘œ âœ… ê¶Œì¥.                        
ì˜ˆ) --cuisine "íŒŒìŠ¤íƒ€","ìŠ¤íŒŒê²Œí‹°"


â–¶ ì‚°ì¶œë¬¼ ì˜ˆì‹œ
1) outputs/places_json/<place_id>_tags.json
   {
     "place_id": "1108161508",
     "store_name": "ì˜¤ë¸”ë¦¬ë„",
     "cuisine": ["íŒŒìŠ¤íƒ€", "ìŠ¤íŒŒê²Œí‹°"],  # CLI --cuisine ìœ¼ë¡œ ì…ë ¥
     "tag_counts": { "ë§›ìˆì–´ìš”": 6, "ì²­ê²°í•´ìš”": 7, ... }
   }

"""


from __future__ import annotations
import time, csv, json, argparse, datetime as dt
from pathlib import Path
from typing import List, Dict, Any
from collections import Counter

# --- Selenium ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# -----------------------------
# URL & Driver
# -----------------------------
def build_review_urls(place_id: str, sort: str = "recent") -> List[str]:
    scopes = ["restaurant", "place"]
    return [
        f"https://m.place.naver.com/{sc}/{place_id}/review/visitor?entry=ple&reviewSort={sort}"
        for sc in scopes
    ]


def make_driver(headless: bool = False) -> webdriver.Chrome:
    opts = webdriver.ChromeOptions()
    if headless:
        opts.add_argument("headless=new")
    opts.add_argument("window-size=1920,1080")
    opts.add_argument("disable-gpu")
    # ë¬´ë‚œí•œ UA
    opts.add_argument(
        "user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)
    driver.implicitly_wait(10)
    return driver

# -----------------------------
# Interactions
# -----------------------------
def click_more_until_end(driver: webdriver.Chrome, max_clicks: int = 50, sleep_sec: float = 0.4):
    # ìŠ¤í¬ë¡¤/ë Œë”ë§ ìœ ë„
    try:
        driver.find_element(By.TAG_NAME, "body").send_keys(Keys.PAGE_DOWN)
        time.sleep(0.4)
    except Exception:
        pass

    # ìš°ì„  ì‹œë„í•  XPATH (ì‹œê¸°/ì¼€ì´ìŠ¤ë³„ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    xpath_candidates = [
        '//*[@id="app-root"]//a[contains(.,"ë”ë³´ê¸°")]',
        '//*[@id="app-root"]//button[contains(.,"ë”ë³´ê¸°")]',
        '//*[@id="app-root"]/div/div/div//a[contains(@href,"review") and contains(.,"ë”ë³´ê¸°")]',
    ]

    clicks = 0
    while clicks < max_clicks:
        clicked = False

        # 1) XPATH ìš°ì„  ì‹œë„
        for xp in xpath_candidates:
            try:
                btn = driver.find_element(By.XPATH, xp)
                if btn.is_displayed():
                    btn.click()
                    clicked = True
                    break
            except (NoSuchElementException, ElementClickInterceptedException):
                continue
            except Exception:
                continue
        if not clicked:
            # 2) CSS ì „ìˆ˜ì¡°ì‚¬: 'ë”ë³´ê¸°' í…ìŠ¤íŠ¸ í¬í•¨ ë§í¬/ë²„íŠ¼
            try:
                for el in driver.find_elements(By.CSS_SELECTOR, "a, button"):
                    try:
                        txt = (el.text or "").strip()
                        if "ë”ë³´ê¸°" in txt and el.is_displayed():
                            el.click()
                            clicked = True
                            break
                    except Exception:
                        continue
            except Exception:
                pass

        if not clicked:
            # ë” ì´ìƒ í´ë¦­í•  'ë”ë³´ê¸°'ê°€ ì—†ë‹¤ê³  íŒë‹¨
            time.sleep(0.6)
            break

        clicks += 1
        time.sleep(sleep_sec)

    return clicks


# -----------------------------
# Parsing
# -----------------------------
# íŒŒì¼ ìƒë‹¨(í•¨ìˆ˜ë“¤ ëª¨ìŒ)ì— ì¶”ê°€
def parse_cuisine_tokens(tokens) -> list[str]:
    if not tokens:
        return []
    s = " ".join(tokens)                  
    parts = [p.strip().strip('\'"') for p in s.split(",")]  
    # ê³µë°±ë§Œ ë„˜ì–´ì˜¨ ê²½ìš° ì •ë¦¬
    out = [p for p in parts if p]
    # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
    seen, dedup = set(), []
    for x in out:
        if x not in seen:
            seen.add(x); dedup.append(x)
    return dedup


def parse_reviews_from_html(html: str, place_id: str, cuisine:list[str],store_name: str) -> List[Dict[str, Any]]:
    from bs4 import BeautifulSoup
    bs = BeautifulSoup(html, "lxml")
    data: List[Dict[str, Any]] = []

    items = bs.select("li.place_app") or bs.select("li")
    for r in items:
        box = r.select_one("div.pui__HLNvmI")
        tags = [s.get_text(strip=True) for s in box.select("span.pui__jhpEyP")] if box else []
        if tags:
            data.append({
                "place_id": str(place_id),
                "cuisine":cuisine or [],
                "store_name": store_name,
                "option_tags": tags,   # ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
            })
    return data

def count_tags(rows: List[Dict[str, Any]], dedup_within_row: bool = False) -> Dict[str, int]:
    c = Counter()
    for r in rows:
        tags = r.get("option_tags") or []
        if not isinstance(tags, (list, tuple)): continue
        items = set(tags) if dedup_within_row else tags
        c.update(t.strip() for t in items if str(t).strip())
    return dict(c)

# -----------------------------
# Save
# -----------------------------
def save_csv(records: List[Dict[str, Any]], place_id: str, cuisine:list[str], store_name: str, out_dir: str = "./outputs") -> str:
    Path(out_dir).mkdir(parents=True, exist_ok=True)
    ts = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    path = Path(out_dir) / f"naver_place_reviews_{place_id}_{ts}.csv"
    with open(path, "w", newline="", encoding="utf-8-sig") as f:
        w = csv.DictWriter(f, fieldnames=["place_id","cuisine","store_name","option_tags_json"])
        w.writeheader()
        for row in records:
            tags = row.get("option_tags") or []
            w.writerow({
                "place_id": str(place_id),
                "cuisine": cuisine,
                "store_name": store_name,
                "option_tags_json": json.dumps(tags, ensure_ascii=False),
            })
    return str(path)

def save_store_tag_json(place_id: str, cuisine: list[str],\
                         store_name: str, tag_counts: Dict[str, int],
                        out_dir: str = "./outputs/places_json") -> str:
    Path(out_dir).mkdir(parents=True, exist_ok=True)
    doc = {"place_id": str(place_id), "cuisine":cuisine or [], "store_name": store_name, "tag_counts": tag_counts}
    path = Path(out_dir) / f"{place_id}_tags.json"
    with open(path, "w", encoding="utf-8") as f:
        json.dump(doc, f, ensure_ascii=False, indent=2)
    return str(path)


# -----------------------------
# Orchestration
# -----------------------------
def fetch_and_build(place_id: str, cuisine:str, store_name: str, sort: str = "recent",
                    max_clicks: int = 50, headless: bool = False,
                    save_csv_also: bool = False, dedup_within_row: bool = False) -> str:
    driver = make_driver(headless=headless)
    try:
        last_err = None
        for url in build_review_urls(place_id, sort=sort):
            try:
                driver.get(url)
                # ìš”ì†Œ ê¸°ì¤€ ëŒ€ê¸°: ë¦¬ë·°/íƒœê·¸ ì»¨í…Œì´ë„ˆ ë“±ì¥
                WebDriverWait(driver, 12).until(EC.any_of(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "li.place_app")),
                    EC.presence_of_element_located((By.CSS_SELECTOR, "div.pui__HLNvmI")),
                ))

                clicks = click_more_until_end(driver, max_clicks=max_clicks, sleep_sec=0.4)
                time.sleep(1.0)  # ë Œë” ì—¬ìœ 
                html = driver.page_source

                rows = parse_reviews_from_html(html, place_id=place_id, cuisine=cuisine, store_name=store_name)
                if not rows:
                    continue

                counts = count_tags(rows, dedup_within_row=dedup_within_row)
                out_json = save_store_tag_json(place_id, cuisine, store_name, counts)
                if save_csv_also:
                    save_csv(rows, place_id, cuisine, store_name)

                print(f"[OK] {len(rows)} reviews, {len(counts)} tags -> {out_json} ({clicks} clicks)")
                return out_json
            except Exception as e:
                last_err = e
                continue

        if last_err:
            raise last_err
        raise RuntimeError("ë¦¬ë·°/íƒœê·¸ ìš”ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.")
    finally:
        driver.quit()

# -----------------------------
# CLI
# -----------------------------
def main(argv=None):
    ap = argparse.ArgumentParser(description="Naver Place â†’ tag_counts.json (one-shot)")
    ap.add_argument("--place_id", required=True)
    ap.add_argument("--store_name", required=True)
    ap.add_argument("--cuisine", "--cusine", dest="cuisine", nargs="+",
                help='ì‰¼í‘œ/ê³µë°± ì•„ë¬´ê±°ë‚˜ë¡œ êµ¬ë¶„: ì˜ˆ) --cuisine "íŒŒìŠ¤íƒ€","ìŠ¤íŒŒê²Œí‹°" ë˜ëŠ” --cuisine íŒŒìŠ¤íƒ€ ìŠ¤íŒŒê²Œí‹°')

    ap.add_argument("--sort", default="recent")
    ap.add_argument("--max_clicks", type=int, default=50)
    ap.add_argument("--headless", action="store_true")
    ap.add_argument("--save_csv", action="store_true", help="CSVë„ í•¨ê»˜ ì €ì¥")
    ap.add_argument("--dedup", action="store_true", help="ë¦¬ë·° ë‚´ë¶€ ì¤‘ë³µ íƒœê·¸ëŠ” 1ë²ˆë§Œ ì¹´ìš´íŠ¸")
    args = ap.parse_args(argv)
    cuisine = parse_cuisine_tokens(args.cuisine)

    out = fetch_and_build(
        place_id=args.place_id,
        cuisine=cuisine,
        store_name=args.store_name,
        sort=args.sort,
        max_clicks=args.max_clicks,
        headless=args.headless,
        save_csv_also=args.save_csv,
        dedup_within_row=args.dedup,
    )
    print(out)

if __name__ == "__main__":
    raise SystemExit(main())